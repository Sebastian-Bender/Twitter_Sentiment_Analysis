{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74677</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that the Windows partition of my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74678</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized that my Mac window partition is ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74679</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized the windows partition of my Mac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74680</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just realized between the windows partition of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74681</th>\n",
       "      <td>Nvidia</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Just like the windows partition of my Mac is l...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74682 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            entity sentiment  \\\n",
       "0      Borderlands  Positive   \n",
       "1      Borderlands  Positive   \n",
       "2      Borderlands  Positive   \n",
       "3      Borderlands  Positive   \n",
       "4      Borderlands  Positive   \n",
       "...            ...       ...   \n",
       "74677       Nvidia  Positive   \n",
       "74678       Nvidia  Positive   \n",
       "74679       Nvidia  Positive   \n",
       "74680       Nvidia  Positive   \n",
       "74681       Nvidia  Positive   \n",
       "\n",
       "                                                    text  \n",
       "0      im getting on borderlands and i will murder yo...  \n",
       "1      I am coming to the borders and I will kill you...  \n",
       "2      im getting on borderlands and i will kill you ...  \n",
       "3      im coming on borderlands and i will murder you...  \n",
       "4      im getting on borderlands 2 and i will murder ...  \n",
       "...                                                  ...  \n",
       "74677  Just realized that the Windows partition of my...  \n",
       "74678  Just realized that my Mac window partition is ...  \n",
       "74679  Just realized the windows partition of my Mac ...  \n",
       "74680  Just realized between the windows partition of...  \n",
       "74681  Just like the windows partition of my Mac is l...  \n",
       "\n",
       "[74682 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('twitter_training.csv', names = ['id', 'entity', 'sentiment', 'text'])\n",
    "df = df[['entity', 'sentiment', 'text']]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>GrandTheftAuto(GTA)</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>⭐️ Toronto is the arts and culture capital of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Today sucked so it’s time to drink wine n play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bought a fraction of Microsoft today. Small wins.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>johnson&amp;johnson</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Johnson &amp; Johnson to stop selling talc baby po...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  entity   sentiment  \\\n",
       "0               Facebook  Irrelevant   \n",
       "1                 Amazon     Neutral   \n",
       "2              Microsoft    Negative   \n",
       "3                  CS-GO    Negative   \n",
       "4                 Google     Neutral   \n",
       "..                   ...         ...   \n",
       "995  GrandTheftAuto(GTA)  Irrelevant   \n",
       "996                CS-GO  Irrelevant   \n",
       "997          Borderlands    Positive   \n",
       "998            Microsoft    Positive   \n",
       "999      johnson&johnson     Neutral   \n",
       "\n",
       "                                                  text  \n",
       "0    I mentioned on Facebook that I was struggling ...  \n",
       "1    BBC News - Amazon boss Jeff Bezos rejects clai...  \n",
       "2    @Microsoft Why do I pay for WORD when it funct...  \n",
       "3    CSGO matchmaking is so full of closet hacking,...  \n",
       "4    Now the President is slapping Americans in the...  \n",
       "..                                                 ...  \n",
       "995  ⭐️ Toronto is the arts and culture capital of ...  \n",
       "996  tHIS IS ACTUALLY A GOOD MOVE TOT BRING MORE VI...  \n",
       "997  Today sucked so it’s time to drink wine n play...  \n",
       "998  Bought a fraction of Microsoft today. Small wins.  \n",
       "999  Johnson & Johnson to stop selling talc baby po...  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = pd.read_csv('twitter_validation.csv', names = ['id', 'entity', 'sentiment', 'text'])\n",
    "df_val = df_val[['entity', 'sentiment', 'text']]\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 74682 entries, 0 to 74681\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   entity     74682 non-null  object\n",
      " 1   sentiment  74682 non-null  object\n",
      " 2   text       73996 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "entity         0\n",
       "sentiment      0\n",
       "text         686\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)\n",
    "df_val.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative      22358\n",
       "Positive      20655\n",
       "Neutral       18108\n",
       "Irrelevant    12875\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Neutral       285\n",
       "Positive      277\n",
       "Negative      266\n",
       "Irrelevant    172\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "sns.countplot(x=df['sentiment'])\n",
    "plt.xlabel('Classes')\n",
    "plt.title('Sentiment Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Positive': 0, 'Neutral': 1, 'Negative': 2, 'Irrelevant': 3}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "for index, sentiment in enumerate(df['sentiment'].unique()):\n",
    "    label_dict[sentiment] = index\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will murder yo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>I am coming to the borders and I will kill you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands and i will kill you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im coming on borderlands and i will murder you...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Borderlands</td>\n",
       "      <td>Positive</td>\n",
       "      <td>im getting on borderlands 2 and i will murder ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity sentiment                                               text  \\\n",
       "0  Borderlands  Positive  im getting on borderlands and i will murder yo...   \n",
       "1  Borderlands  Positive  I am coming to the borders and I will kill you...   \n",
       "2  Borderlands  Positive  im getting on borderlands and i will kill you ...   \n",
       "3  Borderlands  Positive  im coming on borderlands and i will murder you...   \n",
       "4  Borderlands  Positive  im getting on borderlands 2 and i will murder ...   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['sentiment'].replace(label_dict)\n",
    "df_val['label'] = df_val['sentiment'].replace(label_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Facebook</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>I mentioned on Facebook that I was struggling ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amazon</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>BBC News - Amazon boss Jeff Bezos rejects clai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@Microsoft Why do I pay for WORD when it funct...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CS-GO</td>\n",
       "      <td>Negative</td>\n",
       "      <td>CSGO matchmaking is so full of closet hacking,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Now the President is slapping Americans in the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      entity   sentiment                                               text  \\\n",
       "0   Facebook  Irrelevant  I mentioned on Facebook that I was struggling ...   \n",
       "1     Amazon     Neutral  BBC News - Amazon boss Jeff Bezos rejects clai...   \n",
       "2  Microsoft    Negative  @Microsoft Why do I pay for WORD when it funct...   \n",
       "3      CS-GO    Negative  CSGO matchmaking is so full of closet hacking,...   \n",
       "4     Google     Neutral  Now the President is slapping Americans in the...   \n",
       "\n",
       "   label  \n",
       "0      3  \n",
       "1      1  \n",
       "2      2  \n",
       "3      2  \n",
       "4      1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34593</th>\n",
       "      <td>Fortnite</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Big Picture For Deadpool ».. store.playstation...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48031</th>\n",
       "      <td>HomeDepot</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>A car rolled off a parking lot and over an emb...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44817</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>Negative</td>\n",
       "      <td>RhandlerR  Verizon playing the biggest games o...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32417</th>\n",
       "      <td>LeagueOfLegends</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>entire Age of Legends toxic? (please know i’m ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28214</th>\n",
       "      <td>ApexLegends</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@ PlayApex please help! After the hotfix for t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31487</th>\n",
       "      <td>LeagueOfLegends</td>\n",
       "      <td>Positive</td>\n",
       "      <td>i have ever dreamed i are scoring league of ho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20581</th>\n",
       "      <td>WorldOfCraft</td>\n",
       "      <td>Positive</td>\n",
       "      <td>My beloved main character from World of Warcra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55478</th>\n",
       "      <td>CallOfDuty</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Tried cod today, how can people play with it? ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20864</th>\n",
       "      <td>WorldOfCraft</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I've just earned \"Horrible Bosses\"!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30059</th>\n",
       "      <td>ApexLegends</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>&lt;unk&gt; kYOOT. &lt;unk&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73996 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                entity   sentiment  \\\n",
       "34593         Fortnite  Irrelevant   \n",
       "48031        HomeDepot     Neutral   \n",
       "44817          Verizon    Negative   \n",
       "32417  LeagueOfLegends     Neutral   \n",
       "28214      ApexLegends    Negative   \n",
       "...                ...         ...   \n",
       "31487  LeagueOfLegends    Positive   \n",
       "20581     WorldOfCraft    Positive   \n",
       "55478       CallOfDuty     Neutral   \n",
       "20864     WorldOfCraft     Neutral   \n",
       "30059      ApexLegends     Neutral   \n",
       "\n",
       "                                                    text  label  \n",
       "34593  Big Picture For Deadpool ».. store.playstation...      3  \n",
       "48031  A car rolled off a parking lot and over an emb...      1  \n",
       "44817  RhandlerR  Verizon playing the biggest games o...      2  \n",
       "32417  entire Age of Legends toxic? (please know i’m ...      1  \n",
       "28214  @ PlayApex please help! After the hotfix for t...      2  \n",
       "...                                                  ...    ...  \n",
       "31487  i have ever dreamed i are scoring league of ho...      0  \n",
       "20581  My beloved main character from World of Warcra...      0  \n",
       "55478  Tried cod today, how can people play with it? ...      1  \n",
       "20864                I've just earned \"Horrible Bosses\"!      1  \n",
       "30059                                 <unk> kYOOT. <unk>      1  \n",
       "\n",
       "[73996 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.sample(frac=1)\n",
    "df_val = df_val.sample(frac=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(['label'], axis=1)\n",
    "y_train = df['label'].values\n",
    "\n",
    "X_val = df_val.drop(['label'], axis=1)\n",
    "y_val = df_val['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34593</th>\n",
       "      <td>Fortnite</td>\n",
       "      <td>Irrelevant</td>\n",
       "      <td>Big Picture For Deadpool ».. store.playstation...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48031</th>\n",
       "      <td>HomeDepot</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>A car rolled off a parking lot and over an emb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44817</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>Negative</td>\n",
       "      <td>RhandlerR  Verizon playing the biggest games o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32417</th>\n",
       "      <td>LeagueOfLegends</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>entire Age of Legends toxic? (please know i’m ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28214</th>\n",
       "      <td>ApexLegends</td>\n",
       "      <td>Negative</td>\n",
       "      <td>@ PlayApex please help! After the hotfix for t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                entity   sentiment  \\\n",
       "34593         Fortnite  Irrelevant   \n",
       "48031        HomeDepot     Neutral   \n",
       "44817          Verizon    Negative   \n",
       "32417  LeagueOfLegends     Neutral   \n",
       "28214      ApexLegends    Negative   \n",
       "\n",
       "                                                    text  \n",
       "34593  Big Picture For Deadpool ».. store.playstation...  \n",
       "48031  A car rolled off a parking lot and over an emb...  \n",
       "44817  RhandlerR  Verizon playing the biggest games o...  \n",
       "32417  entire Age of Legends toxic? (please know i’m ...  \n",
       "28214  @ PlayApex please help! After the hotfix for t...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 1, 2, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm as tqdm\n",
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/home/sebastian/.local/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:2304: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "encoded_data_train = tokenizer.batch_encode_plus(X_train['text'].values,\n",
    "                                                 add_special_tokens = True,\n",
    "                                                 return_attention_mask = True,\n",
    "                                                 pad_to_max_length = True,\n",
    "                                                 max_length = 280,\n",
    "                                                 return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_val = tokenizer.batch_encode_plus(X_val['text'].values,\n",
    "                                                 add_special_tokens = True,\n",
    "                                                 return_attention_mask = True,\n",
    "                                                 pad_to_max_length = True,\n",
    "                                                 max_length = 280,\n",
    "                                                 return_tensors = 'pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2502,  3861,  ...,     0,     0,     0],\n",
       "        [  101,  1037,  2482,  ...,     0,     0,     0],\n",
       "        [  101,  1054, 11774,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101,  2699, 19429,  ...,     0,     0,     0],\n",
       "        [  101,  1045,  1005,  ...,     0,     0,     0],\n",
       "        [  101,  1026,  4895,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode train set\n",
    "input_ids_train = encoded_data_train['input_ids']\n",
    "attention_masks_train = encoded_data_train['attention_mask']\n",
    "labels_train = torch.tensor(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode train set\n",
    "input_ids_val = encoded_data_val['input_ids']\n",
    "attention_masks_val = encoded_data_val['attention_mask']\n",
    "labels_val = torch.tensor(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataloader\n",
    "dataset_train = TensorDataset(input_ids_train, \n",
    "                              attention_masks_train,\n",
    "                              labels_train)\n",
    "\n",
    "dataset_val = TensorDataset(input_ids_val, \n",
    "                             attention_masks_val, \n",
    "                             labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73996\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(len(dataset_train))\n",
    "print(len(dataset_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Pretrained BERT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertForSequenceClassification\n",
    "\n",
    "#load pre-trained BERT\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased',\n",
    "                                                      num_labels = len(label_dict),\n",
    "                                                      output_attentions = False,\n",
    "                                                      output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "#load train set\n",
    "dataloader_train = DataLoader(dataset_train,\n",
    "                              sampler = RandomSampler(dataset_train),\n",
    "                              batch_size = batch_size)\n",
    "\n",
    "#load val set\n",
    "dataloader_val = DataLoader(dataset_val,\n",
    "                              sampler = RandomSampler(dataset_val),\n",
    "                              batch_size = 32) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sebastian/.local/lib/python3.8/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "epochs = 10\n",
    "\n",
    "#load optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-5, eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                            num_warmup_steps = 0,\n",
    "                                            num_training_steps = len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "#f1 score\n",
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy score\n",
    "def accuracy_per_class(preds, labels):\n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    \n",
    "    #make prediction\n",
    "    preds_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    \n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat==label]\n",
    "        y_true = labels_flat[labels_flat==label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy:{len(y_preds[y_preds==label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    #evaluation mode disables the dropout layer \n",
    "    model.eval()\n",
    "    \n",
    "    #tracking variables\n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):\n",
    "        \n",
    "        #load into GPU\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        #define inputs\n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2]}\n",
    "\n",
    "        #compute logits\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        #compute loss\n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        #compute accuracy\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    #compute average loss\n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  7.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Epoch 1 Train: 0.8433271738065256, Val F1 Score: 0.8639567160139138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Epoch 2 Train: 0.4027197831591239, Val F1 Score: 0.9519861446768466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Epoch 3 Train: 0.20994188574069758, Val F1 Score: 0.9619234791258834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Epoch 4 Train: 0.13702985365126233, Val F1 Score: 0.9659288189672368\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Epoch 5 Train: 0.10240704245821768, Val F1 Score: 0.965019794335435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Epoch 6 Train: 0.08233311846778521, Val F1 Score: 0.9699852613855737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Epoch 7 Train: 0.06786266711940107, Val F1 Score: 0.9669435212074127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Epoch 8 Train: 0.05904138748482109, Val F1 Score: 0.9679960936272713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  7.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Epoch 9 Train: 0.053072778988064805, Val F1 Score: 0.962934394785291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss Epoch 10 Train: 0.0493705910306866, Val F1 Score: 0.9649525605414218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs+1):\n",
    "\n",
    "    #set model in train mode\n",
    "    model.train()\n",
    "\n",
    "    #tracking variable\n",
    "    loss_train_total = 0\n",
    "    \n",
    "    \n",
    "    for batch in dataloader_train:\n",
    "        #set gradient to 0\n",
    "        model.zero_grad()\n",
    "\n",
    "        #load into GPU\n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "\n",
    "        #define inputs\n",
    "        inputs = {'input_ids': batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels': batch[2]}\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[0] #output.loss\n",
    "        loss_train_total +=loss.item()\n",
    "\n",
    "        #backward pass to get gradients\n",
    "        loss.backward()\n",
    "        \n",
    "        #clip the norm of the gradients to 1.0 to prevent exploding gradients\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        \n",
    "        #update optimizer\n",
    "        optimizer.step()\n",
    "\n",
    "        #update scheduler\n",
    "        scheduler.step()\n",
    "        \n",
    "        #progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})     \n",
    "    \n",
    "    #tqdm.write('\\nEpoch {epoch}')\n",
    "    \n",
    "    #print training result\n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
    "    #tqdm.write(f'Training loss: {loss_train_avg}')\n",
    "    \n",
    "    #evaluate\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    #f1 score\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    #tqdm.write(f'Validation loss: {val_loss}')\n",
    "    #tqdm.write(f'F1 Score (weighted): {val_f1}')\n",
    "    print(f'Loss Epoch {epoch} Train: {loss_train_avg}, Val F1 Score: {val_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:04<00:00,  7.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: Positive\n",
      "Accuracy:271/277\n",
      "\n",
      "Class: Neutral\n",
      "Accuracy:273/285\n",
      "\n",
      "Class: Negative\n",
      "Accuracy:261/266\n",
      "\n",
      "Class: Irrelevant\n",
      "Accuracy:160/172\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#evaluate\n",
    "_, predictions, true_vals = evaluate(dataloader_val)\n",
    "#get accuracy score\n",
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.cpu().state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
